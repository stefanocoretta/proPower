[
  {
    "objectID": "data/song2020/shallow.html",
    "href": "data/song2020/shallow.html",
    "title": "Second language users exhibit shallow morphological processing",
    "section": "",
    "text": "Group\n\nParticipant group (L1, L2).\n\nID\n\nSubject unique identifier.\n\nList\n\nWord list.\n\nTarget\n\nTarget word.\n\nRT\n\nReaction time (ms).\n\nRT_log\n\nLogged reaction time.\n\nCritical_Filler\n\nWhether the trial is a critical or a filler trial.\n\nWord_Nonword\n\nWhether the word is a real word or a nonce word (only word is present in the data).\n\nRelation_type\n\nWhether the relation type is Unrelated, Constituent, or NonConstituent.\n\nBranching\n\nWhether the trial word is Left-branching or Right-branching."
  },
  {
    "objectID": "data/song2020/shallow.html#description",
    "href": "data/song2020/shallow.html#description",
    "title": "Second language users exhibit shallow morphological processing",
    "section": "",
    "text": "Group\n\nParticipant group (L1, L2).\n\nID\n\nSubject unique identifier.\n\nList\n\nWord list.\n\nTarget\n\nTarget word.\n\nRT\n\nReaction time (ms).\n\nRT_log\n\nLogged reaction time.\n\nCritical_Filler\n\nWhether the trial is a critical or a filler trial.\n\nWord_Nonword\n\nWhether the word is a real word or a nonce word (only word is present in the data).\n\nRelation_type\n\nWhether the relation type is Unrelated, Constituent, or NonConstituent.\n\nBranching\n\nWhether the trial word is Left-branching or Right-branching."
  },
  {
    "objectID": "slides/index.html#frequentist-statistics",
    "href": "slides/index.html#frequentist-statistics",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Frequentist statistics",
    "text": "Frequentist statistics\n\n\nP-values: \\(P(d|H)\\), probability of the difference \\(d\\) (or a more extreme one) given the hypothesis \\(H\\).\nNeyman-Pearson NHST:\n\n\\(H\\) is the “null hypothesis”, to be rejected.\n\\(\\alpha\\) level: \\(p \\ge \\alpha\\) non-significant difference, \\(p &lt; \\alpha\\) significant difference.\n\\(\\beta\\) level: statistical power, probability of detecting a significant difference when there is one.\n\nNull Ritual (Gigerenzer 2004, 2018; Gigerenzer, Krauss, and Vitouch 2004):\n\n\\(H\\) is a “nil hypothesis”: \\(d = 0\\), to be rejected.\n\\(\\alpha = 0.05\\)\n\\(\\beta = 0.8\\)"
  },
  {
    "objectID": "slides/index.html#statistical-power",
    "href": "slides/index.html#statistical-power",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Statistical power",
    "text": "Statistical power\n\n\nStatistical power (\\(\\beta\\) level) is affected by sample size.\nOne must determine the sample size needed to achieve the desired statistical power. In Null Ritualistic statistics this is 0.8 (or 80% power).\nProspective power analysis.\n\n\n\n\nTwo examples\n\nEffect of consonant voicing on vowel duration in mono- vs disyllabic words.\nAccuracy in a lexical decision task to investigate shallow morphological representation in L2 speakers."
  },
  {
    "objectID": "slides/index.html#example-1-vowel-duration",
    "href": "slides/index.html#example-1-vowel-duration",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Example 1: vowel duration",
    "text": "Example 1: vowel duration\n\n\nData from Coretta (2019b), Coretta (2019a).\n“Voicing effect” in Manchester English.\nMono- and di-syllabic nonce words in frame sentences.\nIs the voicing effect the same or different in mono- vs disyllabic words?\n\n\n\n\n\nUse “pilot” data to determine sample size."
  },
  {
    "objectID": "slides/index.html#example-1-the-data",
    "href": "slides/index.html#example-1-the-data",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Example 1: the data",
    "text": "Example 1: the data\n\nlibrary(tidyverse)\n\neng_s &lt;- readRDS(\"data/eng_s.rds\")\neng_s |&gt; select(speaker, num_syl, word, voicing, v1_duration, speech_rate_c)\n\n# A tibble: 720 × 6\n   speaker num_syl word   voicing   v1_duration speech_rate_c\n   &lt;fct&gt;   &lt;fct&gt;   &lt;fct&gt;  &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;\n 1 en02    di      teegus voiced          117.         -0.650\n 2 en02    mono    teek   voiceless        95.0        -0.908\n 3 en02    mono    teek   voiceless       106.         -0.900\n 4 en02    di      tergus voiced          190.         -0.750\n 5 en02    di      targus voiced          195.         -0.383\n 6 en02    di      teepus voiceless       113.         -0.655\n 7 en02    mono    terb   voiced          203.         -0.823\n 8 en02    mono    tarp   voiceless       217.         -0.534\n 9 en02    di      teegus voiced          120.         -0.571\n10 en02    di      terpus voiceless       147.         -0.665\n# ℹ 710 more rows"
  },
  {
    "objectID": "slides/index.html#effect-of-voicing-on-vowel-duration",
    "href": "slides/index.html#effect-of-voicing-on-vowel-duration",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Effect of voicing on vowel duration",
    "text": "Effect of voicing on vowel duration"
  },
  {
    "objectID": "slides/index.html#prospective-power-analysis-overview",
    "href": "slides/index.html#prospective-power-analysis-overview",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Prospective power analysis: overview",
    "text": "Prospective power analysis: overview\n\n\nDetermine Smallest Meaningful Effect Size (SMES).\nRun regression model on pilot or simulated data.\nExtend model with simr::extend() and set coefficient to SMES.\nRun power calculation with simr::powerCurve()."
  },
  {
    "objectID": "slides/index.html#smallest-meaningful-effect-size",
    "href": "slides/index.html#smallest-meaningful-effect-size",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Smallest Meaningful Effect Size",
    "text": "Smallest Meaningful Effect Size\n\n\nThe minimum standard deviation for measurements of vowel duration is between 2 to 5 ms (Allen 1978).\nNowak (2006) finds an effect of voicing of 4.5 ms.\nLet’s use an SMES of 5 ms. What does this correspond to as a difference ratio?"
  },
  {
    "objectID": "slides/index.html#smallest-meaningful-effect-size-ratios",
    "href": "slides/index.html#smallest-meaningful-effect-size-ratios",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Smallest Meaningful Effect Size (ratios)",
    "text": "Smallest Meaningful Effect Size (ratios)\n\n\nx &lt;- seq(50, 300, by = 10)\ny &lt;- x + 5\n\nggplot() +\n  aes(x, y/x) +\n  geom_point(size = 2) +\n  labs(\n    x = \"Vowel duration\",\n    y = \"Difference ratio\"\n  )"
  },
  {
    "objectID": "slides/index.html#run-regression-model",
    "href": "slides/index.html#run-regression-model",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Run regression model",
    "text": "Run regression model\n\ndur_lm &lt;- lmer(\n  log(v1_duration) ~\n    voicing + num_syl + voicing:num_syl + speech_rate_c +\n    (voicing | speaker),\n  data = eng_s\n)\n\nsummary(dur_lm)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: \nlog(v1_duration) ~ voicing + num_syl + voicing:num_syl + speech_rate_c +  \n    (voicing | speaker)\n   Data: eng_s\n\nREML criterion at convergence: -230\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3800 -0.5941  0.1648  0.6624  3.1393 \n\nRandom effects:\n Groups   Name          Variance  Std.Dev. Corr\n speaker  (Intercept)   0.0181967 0.13490      \n          voicingvoiced 0.0004701 0.02168  0.37\n Residual               0.0397878 0.19947      \nNumber of obs: 720, groups:  speaker, 6\n\nFixed effects:\n                          Estimate Std. Error t value\n(Intercept)                4.66722    0.05705  81.816\nvoicingvoiced              0.17276    0.02281   7.573\nnum_sylmono                0.08260    0.02308   3.579\nspeech_rate_c             -0.22902    0.02985  -7.673\nvoicingvoiced:num_sylmono  0.05501    0.02974   1.850\n\nCorrelation of Fixed Effects:\n            (Intr) vcngvc nm_syl spch__\nvoicingvocd -0.029                     \nnum_sylmono -0.163  0.417              \nspeech_rt_c  0.011 -0.006  0.412       \nvcngvcd:nm_  0.130 -0.652 -0.647 -0.006"
  },
  {
    "objectID": "slides/index.html#extend-model-and-set-smes",
    "href": "slides/index.html#extend-model-and-set-smes",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Extend model and set SMES",
    "text": "Extend model and set SMES\n\ndur_lm_ext &lt;- extend(dur_lm, along = \"speaker\", n = 20)\n\nfixef(dur_lm_ext)[\"voicingvoiced:num_sylmono\"] &lt;- 0.03\nfixef(dur_lm_ext)\n\n              (Intercept)             voicingvoiced               num_sylmono \n               4.66722417                0.17276388                0.08260109 \n            speech_rate_c voicingvoiced:num_sylmono \n              -0.22902490                0.03000000"
  },
  {
    "objectID": "slides/index.html#run-power-analysis",
    "href": "slides/index.html#run-power-analysis",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Run power analysis",
    "text": "Run power analysis\n\nlibrary(simr)\n\ndur_lm_pow &lt;- powerCurve(\n  dur_lm_ext,\n  fixed(\"voicing:num_syl\"),\n  along = \"speaker\",\n  breaks = c(50, 70, 100)\n)\n\nprint(dur_lm_pow)\n\n\n\nPower for predictor 'voicing:num_syl', (95% confidence interval),\nby number of levels in speaker:\n     50: 83.30% (80.84, 85.56) - 6000 rows\n     70: 92.90% (91.13, 94.41) - 8400 rows\n    100: 98.90% (98.04, 99.45) - 12000 rows\n\nTime elapsed: 1 h 12 m 47 s"
  },
  {
    "objectID": "slides/index.html#power-curve-plot",
    "href": "slides/index.html#power-curve-plot",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Power curve plot",
    "text": "Power curve plot\n\nplot(dur_lm_pow)"
  },
  {
    "objectID": "slides/index.html#example-2-accuracy",
    "href": "slides/index.html#example-2-accuracy",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Example 2: accuracy",
    "text": "Example 2: accuracy\n\n\nData from Song et al. (2020).\nShallow morphological representation in L2 speakers.\nLexical decision task: Is the word a real English word or not?\nPriming paradigm:\n\nPrime: prolong (unrelated), unkind (constituent), kindness (non-constituent).\nTarget: unkindness ([un-kind]-ness, not un-[kind-ness]).\n\nConstituent vs non-constituent accuracy in L2 speakers."
  },
  {
    "objectID": "slides/index.html#example-2-the-data",
    "href": "slides/index.html#example-2-the-data",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Example 2: the data",
    "text": "Example 2: the data\n\nshallow_s &lt;- readRDS(\"data/shallow_s.rds\")\nshallow_s\n\n# A tibble: 180 × 11\n   ID    Group List  Target         ACC    RT logRT Critical_Filler Word_Nonword\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;       \n 1 L2_36 L2    D     unholiness       1   878  6.78 Critical        Word        \n 2 L2_36 L2    D     rehydratable     1  1263  7.14 Critical        Word        \n 3 L2_36 L2    D     unclearness      1  1296  7.17 Critical        Word        \n 4 L2_36 L2    D     resellable       1  1344  7.20 Critical        Word        \n 5 L2_36 L2    D     unsharpness      0  1192  7.08 Critical        Word        \n 6 L2_36 L2    D     reattachable     1   969  6.88 Critical        Word        \n 7 L2_36 L2    D     uncleverness     0   835  6.73 Critical        Word        \n 8 L2_36 L2    D     unwariness       1  1028  6.94 Critical        Word        \n 9 L2_36 L2    D     reclosable       1  1028  6.94 Critical        Word        \n10 L2_36 L2    D     reusable         1   814  6.70 Critical        Word        \n# ℹ 170 more rows\n# ℹ 2 more variables: Relation_type &lt;chr&gt;, Branching &lt;chr&gt;"
  },
  {
    "objectID": "slides/index.html#accuracy-by-relation-type",
    "href": "slides/index.html#accuracy-by-relation-type",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Accuracy by relation type",
    "text": "Accuracy by relation type"
  },
  {
    "objectID": "slides/index.html#smallest-meaningful-effect-size-log-odds",
    "href": "slides/index.html#smallest-meaningful-effect-size-log-odds",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Smallest Meaningful Effect Size (log-odds)",
    "text": "Smallest Meaningful Effect Size (log-odds)\n\n\nI have no idea…\nSay -0.2 (log-odds)."
  },
  {
    "objectID": "slides/index.html#smallest-meaningful-effect-size-probability",
    "href": "slides/index.html#smallest-meaningful-effect-size-probability",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Smallest Meaningful Effect Size (probability)",
    "text": "Smallest Meaningful Effect Size (probability)"
  },
  {
    "objectID": "slides/index.html#run-regression-model-1",
    "href": "slides/index.html#run-regression-model-1",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Run regression model",
    "text": "Run regression model\n\nsha_lm &lt;- glmer(\n  ACC ~ Relation_type + (Relation_type | ID),\n  family = binomial,\n  data = shallow_s\n)\n\nsummary(sha_lm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: ACC ~ Relation_type + (Relation_type | ID)\n   Data: shallow_s\n\n     AIC      BIC   logLik deviance df.resid \n   243.9    272.7   -113.0    225.9      171 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.8220 -1.1732  0.5994  0.7376  0.9667 \n\nRandom effects:\n Groups Name                        Variance Std.Dev. Corr       \n ID     (Intercept)                 0.5606   0.7487              \n        Relation_typeNonConstituent 0.1617   0.4022   -1.00      \n        Relation_typeUnrelated      0.2396   0.4895   -1.00  1.00\nNumber of obs: 180, groups:  ID, 10\n\nFixed effects:\n                              Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)                  0.8699404  0.3904283   2.228   0.0259 *\nRelation_typeNonConstituent  0.0008542  0.4401554   0.002   0.9985  \nRelation_typeUnrelated      -0.3867280  0.4379963  -0.883   0.3773  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) Rlt_NC\nRltn_typNnC -0.730       \nRltn_typUnr -0.777  0.596\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00637234 (tol = 0.002, component 1)"
  },
  {
    "objectID": "slides/index.html#run-regression-model-ii",
    "href": "slides/index.html#run-regression-model-ii",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Run regression model II",
    "text": "Run regression model II\n\nsha_lm_2 &lt;- glmer(\n  ACC ~ Relation_type + (1 | ID),\n  family = binomial,\n  data = shallow_s\n)\n\nsummary(sha_lm_2)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: ACC ~ Relation_type + (1 | ID)\n   Data: shallow_s\n\n     AIC      BIC   logLik deviance df.resid \n   235.1    247.8   -113.5    227.1      176 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.7702 -1.2415  0.6161  0.7087  0.9373 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n ID     (Intercept) 0.14     0.3742  \nNumber of obs: 180, groups:  ID, 10\n\nFixed effects:\n                            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)                  0.79468    0.30687   2.590  0.00961 **\nRelation_typeNonConstituent  0.08048    0.40084   0.201  0.84086   \nRelation_typeUnrelated      -0.30295    0.38990  -0.777  0.43716   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) Rlt_NC\nRltn_typNnC -0.643       \nRltn_typUnr -0.665  0.506"
  },
  {
    "objectID": "slides/index.html#run-power-analysis-1",
    "href": "slides/index.html#run-power-analysis-1",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Run power analysis",
    "text": "Run power analysis\n\nsha_lm_ext &lt;- extend(sha_lm_2), along = \"ID\", n = 1000)\nfixef(sha_lm_ext)[\"Relation_typeNonConstituent\"] &lt;- -0.2\n\nsha_lm_pow &lt;- powerCurve(sha_lm_ext, fixed(\"Relation_typeNonConstituent\"), along = \"ID\")\nprint(sha_lm_pow)\n\n\n\nPower for predictor 'Relation_typeNonConstituent', (95% confidence interval),\nby largest value of ID:\n      3:  5.00% ( 3.73,  6.54) - 54 rows\n    114: 37.50% (34.49, 40.58) - 2052 rows\n    225: 67.60% (64.60, 70.50) - 4050 rows\n    335: 83.30% (80.84, 85.56) - 6030 rows\n    446: 92.40% (90.58, 93.97) - 8028 rows\n    557: 95.70% (94.25, 96.87) - 10026 rows\n    668: 98.30% (97.29, 99.01) - 12024 rows\n    778: 99.20% (98.43, 99.65) - 14004 rows\n    889: 99.70% (99.13, 99.94) - 16002 rows\n   1000: 100.0% (99.63, 100.0) - 18000 rows\n\nTime elapsed: 1 h 29 m 48 s"
  },
  {
    "objectID": "slides/index.html#power-curve-plot-1",
    "href": "slides/index.html#power-curve-plot-1",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Power curve plot",
    "text": "Power curve plot\n\nplot(sha_lm_pow)"
  },
  {
    "objectID": "slides/index.html#summary",
    "href": "slides/index.html#summary",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "Summary",
    "text": "Summary\n\n\nDetermine Smallest Meaningful Effect Size (SMES).\nRun regression model on pilot or simulated data.\nExtend model with simr::extend() and set coefficient to SMES.\nRun power calculation with simr::powerCurve().\n\n\n\n\nQuestions?"
  },
  {
    "objectID": "slides/index.html#references",
    "href": "slides/index.html#references",
    "title": "proPower: Prospective power analyses for frequentist regression models",
    "section": "References",
    "text": "References\n\n\nAllen, George D. 1978. “Vowel Duration Measurement: A Reliability Study.” The Journal of the Acoustical Society of America 63 (4): 11761185. https://doi.org/10.1121/1.381826.\n\n\nCoretta, Stefano. 2019a. “Compensatory Aspects of the Effect of Voicing on Vowel Duration in English [Data V1.0.0].” https://doi.org/10.17605/OSF.IO/EP8WB.\n\n\n———. 2019b. “Temporal (in)stability in English Monosyllabic and Disyllabic Words: Insights on the Effect of Voicing on Vowel Duration.” https://doi.org/10.31219/osf.io/jvwa8.\n\n\nGigerenzer, Gerd. 2004. “Mindless Statistics.” The Journal of Socio-Economics 33 (5): 587606. https://doi.org/10.1016/j.socec.2004.09.033.\n\n\n———. 2018. “Statistical Rituals: The Replication Delusion and How We Got There.” Advances in Methods and Practices in Psychological Science 1 (2): 198218. https://doi.org/10.1177/2515245918771329.\n\n\nGigerenzer, Gerd, Stefan Krauss, and Oliver Vitouch. 2004. “The Null Ritual. What You Always Wanted to Know about Significance Testing but Were Afraid to Ask.” In, 391408.\n\n\nNowak, Pawel. 2006. “Vowel Reduction in Polish.” PhD thesis.\n\n\nSong, Yoonsang, Youngah Do, Arthur L. Thompson, Eileen R. Waegemaekers, and Jongbong Lee. 2020. “Second Language Users Exhibit Shallow Morphological Processing.” Studies in Second Language Acquisition 42 (5): 1121–36. https://doi.org/10.1017/s0272263120000170."
  },
  {
    "objectID": "code/02-accuracy.html",
    "href": "code/02-accuracy.html",
    "title": "02-shallow",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggeffects)\nlibrary(simr)\n\nLoading required package: lme4\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nAttaching package: 'simr'\n\nThe following object is masked from 'package:lme4':\n\n    getData\n\nThe following object is masked from 'package:stringr':\n\n    fixed\n\n\n\nshallow &lt;- read_csv(\"data/song2020/shallow.csv\")\n\nRows: 6500 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Group, ID, List, Target, Critical_Filler, Word_Nonword, Relation_ty...\ndbl (3): ACC, RT, logRT\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nshallow_l2 &lt;- shallow |&gt; \n  filter(Group == \"L2\", Branching == \"Left\")\n\nset.seed(9823)\nshallow_s &lt;- shallow_l2 |&gt; \n  distinct(ID) |&gt; \n  slice_sample(n = 10) |&gt; \n  inner_join(shallow_l2, by = \"ID\") |&gt; \n  filter(Branching == \"Left\") |&gt; \n  droplevels()\n\nsaveRDS(shallow_s, \"data/shallow_s.rds\")\nunique(shallow_s$ID)\n\n [1] \"L2_36\" \"L2_18\" \"L2_35\" \"L2_24\" \"L2_03\" \"L2_11\" \"L2_37\" \"L2_10\" \"L2_30\"\n[10] \"L2_26\"\n\n\n\nsha_lm &lt;- glmer(\n  ACC ~ Relation_type + (Relation_type | ID),\n  family = binomial,\n  data = shallow_s\n)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00637234 (tol = 0.002, component 1)\n\nsummary(sha_lm)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: ACC ~ Relation_type + (Relation_type | ID)\n   Data: shallow_s\n\n     AIC      BIC   logLik deviance df.resid \n   243.9    272.7   -113.0    225.9      171 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.8220 -1.1732  0.5994  0.7376  0.9667 \n\nRandom effects:\n Groups Name                        Variance Std.Dev. Corr       \n ID     (Intercept)                 0.5606   0.7487              \n        Relation_typeNonConstituent 0.1617   0.4022   -1.00      \n        Relation_typeUnrelated      0.2396   0.4895   -1.00  1.00\nNumber of obs: 180, groups:  ID, 10\n\nFixed effects:\n                              Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)                  0.8699404  0.3904283   2.228   0.0259 *\nRelation_typeNonConstituent  0.0008542  0.4401554   0.002   0.9985  \nRelation_typeUnrelated      -0.3867280  0.4379963  -0.883   0.3773  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) Rlt_NC\nRltn_typNnC -0.730       \nRltn_typUnr -0.777  0.596\noptimizer (Nelder_Mead) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00637234 (tol = 0.002, component 1)\n\n\n\nsha_lm_2 &lt;- glmer(\n  ACC ~ Relation_type + (1 | ID),\n  family = binomial,\n  data = shallow_s\n)\n\nsummary(sha_lm_2)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: ACC ~ Relation_type + (1 | ID)\n   Data: shallow_s\n\n     AIC      BIC   logLik deviance df.resid \n   235.1    247.8   -113.5    227.1      176 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.7702 -1.2415  0.6161  0.7087  0.9373 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n ID     (Intercept) 0.14     0.3742  \nNumber of obs: 180, groups:  ID, 10\n\nFixed effects:\n                            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)                  0.79468    0.30687   2.590  0.00961 **\nRelation_typeNonConstituent  0.08048    0.40084   0.201  0.84086   \nRelation_typeUnrelated      -0.30295    0.38990  -0.777  0.43716   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) Rlt_NC\nRltn_typNnC -0.643       \nRltn_typUnr -0.665  0.506\n\n\n\nsha_lm_ext &lt;- extend(sha_lm_2, along = \"ID\", n = 1000)\nfixef(sha_lm_ext)[\"Relation_typeNonConstituent\"] &lt;- -0.2\n\nfi &lt;- \"cache/sha_lm_pow.rds\"\n\nif (file.exists(fi)) {\n  sha_lm_pow &lt;- readRDS(fi)\n} else {\n  suppressMessages(\n    sha_lm_pow &lt;- powerCurve(sha_lm_ext, fixed(\"Relation_typeNonConstituent\"), along = \"ID\")\n  )\n  # The following is needed in this case probably because of a bug in powerCurve()\n  sha_lm_pow[[\"xval\"]] &lt;- sha_lm_pow[[\"nlevels\"]]\n  saveRDS(sha_lm_pow, fi)\n}\n\n\nprint(sha_lm_pow)\n\nPower for predictor 'Relation_typeNonConstituent', (95% confidence interval),\nby largest value of ID:\n      3:  5.00% ( 3.73,  6.54) - 54 rows\n    114: 37.50% (34.49, 40.58) - 2052 rows\n    225: 67.60% (64.60, 70.50) - 4050 rows\n    335: 83.30% (80.84, 85.56) - 6030 rows\n    446: 92.40% (90.58, 93.97) - 8028 rows\n    557: 95.70% (94.25, 96.87) - 10026 rows\n    668: 98.30% (97.29, 99.01) - 12024 rows\n    778: 99.20% (98.43, 99.65) - 14004 rows\n    889: 99.70% (99.13, 99.94) - 16002 rows\n   1000: 100.0% (99.63, 100.0) - 18000 rows\n\nTime elapsed: 1 h 29 m 48 s\n\n\n\nplot(sha_lm_pow)"
  },
  {
    "objectID": "code/01-vowel-duration.html",
    "href": "code/01-vowel-duration.html",
    "title": "Prepare data",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggeffects)\nlibrary(simr)\n\nLoading required package: lme4\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nAttaching package: 'simr'\n\nThe following object is masked from 'package:lme4':\n\n    getData\n\nThe following object is masked from 'package:stringr':\n\n    fixed\n\nlibrary(coretta2019eng)\ndata(\"eng_durations\")\n\n\nset.seed(9872)\neng_s &lt;- eng_durations |&gt;\n  distinct(speaker) |&gt; \n  slice_sample(n = 6) |&gt; \n  inner_join(eng_durations, by = \"speaker\") |&gt; \n  droplevels()\nunique(eng_s$speaker)\n\n[1] en02 en11 en01 en04 en03 en07\nLevels: en01 en02 en03 en04 en07 en11\n\nsaveRDS(eng_s, \"data/eng_s.rds\")\n\n\neng_s |&gt; \n  ggplot(aes(voicing, v1_duration)) +\n  geom_jitter() +\n  facet_grid(cols = vars(num_syl))\n\n\n\n\n\n\n\n\n\ndur_lm &lt;- lmer(\n  log(v1_duration) ~ voicing + num_syl + voicing:num_syl + speech_rate_c + (voicing | speaker),\n  data = eng_s\n)\n\n\nsummary(dur_lm)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: \nlog(v1_duration) ~ voicing + num_syl + voicing:num_syl + speech_rate_c +  \n    (voicing | speaker)\n   Data: eng_s\n\nREML criterion at convergence: -230\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3800 -0.5941  0.1648  0.6624  3.1393 \n\nRandom effects:\n Groups   Name          Variance  Std.Dev. Corr\n speaker  (Intercept)   0.0181967 0.13490      \n          voicingvoiced 0.0004701 0.02168  0.37\n Residual               0.0397878 0.19947      \nNumber of obs: 720, groups:  speaker, 6\n\nFixed effects:\n                          Estimate Std. Error t value\n(Intercept)                4.66722    0.05705  81.816\nvoicingvoiced              0.17276    0.02281   7.573\nnum_sylmono                0.08260    0.02308   3.579\nspeech_rate_c             -0.22902    0.02985  -7.673\nvoicingvoiced:num_sylmono  0.05501    0.02974   1.850\n\nCorrelation of Fixed Effects:\n            (Intr) vcngvc nm_syl spch__\nvoicingvocd -0.029                     \nnum_sylmono -0.163  0.417              \nspeech_rt_c  0.011 -0.006  0.412       \nvcngvcd:nm_  0.130 -0.652 -0.647 -0.006\n\n\n\nggpredict(dur_lm, c(\"voicing\", \"num_syl\"))\n\nModel has log-transformed response. Back-transforming predictions to\n  original response scale. Standard errors are still on the transformed\n  scale.\n\n\n# Predicted values of v1_duration\n\nnum_syl: di\n\nvoicing   | Predicted |         95% CI\n--------------------------------------\nvoiceless |    110.79 |  99.01, 123.96\nvoiced    |    131.68 | 116.82, 148.43\n\nnum_syl: mono\n\nvoicing   | Predicted |         95% CI\n--------------------------------------\nvoiceless |    120.33 | 107.53, 134.64\nvoiced    |    151.11 | 134.06, 170.32\n\nAdjusted for:\n* speech_rate_c = -0.18\n*       speaker = 0 (population-level)\n\n\n\ndur_lm_ext &lt;- extend(dur_lm, along = \"speaker\", n = 100)\nfixef(dur_lm_ext)[\"voicingvoiced:num_sylmono\"] &lt;- 0.03\n\nfi &lt;- \"cache/dur_lm_pow.rds\"\n\nif (file.exists(fi)) {\n  dur_lm_pow &lt;- readRDS(fi)\n} else {\n  suppressMessages(\n    dur_lm_pow &lt;- powerCurve(dur_lm_ext, fixed(\"voicing:num_syl\"), along = \"speaker\", breaks = c(50, 70, 100)) \n  )\n  saveRDS(dur_lm_pow, fi)\n}\n\n\nprint(dur_lm_pow)\n\nPower for predictor 'voicing:num_syl', (95% confidence interval),\nby number of levels in speaker:\n     50: 83.30% (80.84, 85.56) - 6000 rows\n     70: 92.90% (91.13, 94.41) - 8400 rows\n    100: 98.90% (98.04, 99.45) - 12000 rows\n\nTime elapsed: 1 h 12 m 47 s\n\nplot(dur_lm_pow)\n\n\n\n\n\n\n\n\n\nx &lt;- seq(50, 200, by = 10)\ny &lt;- x + 5\nplot(x, y/x)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "proPower",
    "section": "",
    "text": "This is the website of the workshop Prospective power analyses for frequentist regression models, part of the STeW series (Statistical Training Workshops) of the Linguistics and English Language department of the University of Edinburgh.\nThe slides are linked in the main menu and you can find data and code in the GitHub repository: https://github.com/stefanocoretta/proPower.\n\n\n\n\n\n\n\nLevel\n🟠 Intermediate\n\n\nDescription\nYou will learn how to perform prospective power analyses for regression/linear models fitted with the frequentist lme4 package. Power analyses are a necessary (albeit always neglected) component of frequentist analyses, since they help the researcher determine the required sample size. Much of the replicability crisis we are facing is due to lack of statistical power (aka low sample sizes) in virtually all published studies.\n\n\nPrerequisites\nNeed to be familiar with regression/linear models in R including models with random effects and binomial/Bernoulli (aka logistic) regressions."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]