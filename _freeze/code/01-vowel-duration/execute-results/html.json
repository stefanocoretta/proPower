{
  "hash": "3d5b1b5166f16b4c6210680b8e8f6930",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Prepare data\"\nauthor: \"Stefano\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggeffects)\nlibrary(simr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: lme4\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nAttaching package: 'simr'\n\nThe following object is masked from 'package:lme4':\n\n    getData\n\nThe following object is masked from 'package:stringr':\n\n    fixed\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(coretta2019eng)\ndata(\"eng_durations\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(9872)\neng_s <- eng_durations |>\n  distinct(speaker) |> \n  slice_sample(n = 6) |> \n  inner_join(eng_durations, by = \"speaker\") |> \n  droplevels()\nunique(eng_s$speaker)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] en02 en11 en01 en04 en03 en07\nLevels: en01 en02 en03 en04 en07 en11\n```\n\n\n:::\n\n```{.r .cell-code}\nsaveRDS(eng_s, \"data/eng_s.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\neng_s |> \n  ggplot(aes(voicing, v1_duration)) +\n  geom_jitter() +\n  facet_grid(cols = vars(num_syl))\n```\n\n::: {.cell-output-display}\n![](01-vowel-duration_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndur_lm <- lmer(\n  log(v1_duration) ~ voicing + num_syl + voicing:num_syl + speech_rate_c + (voicing | speaker),\n  data = eng_s\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(dur_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: \nlog(v1_duration) ~ voicing + num_syl + voicing:num_syl + speech_rate_c +  \n    (voicing | speaker)\n   Data: eng_s\n\nREML criterion at convergence: -230\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3800 -0.5941  0.1648  0.6624  3.1393 \n\nRandom effects:\n Groups   Name          Variance  Std.Dev. Corr\n speaker  (Intercept)   0.0181967 0.13490      \n          voicingvoiced 0.0004701 0.02168  0.37\n Residual               0.0397878 0.19947      \nNumber of obs: 720, groups:  speaker, 6\n\nFixed effects:\n                          Estimate Std. Error t value\n(Intercept)                4.66722    0.05705  81.816\nvoicingvoiced              0.17276    0.02281   7.573\nnum_sylmono                0.08260    0.02308   3.579\nspeech_rate_c             -0.22902    0.02985  -7.673\nvoicingvoiced:num_sylmono  0.05501    0.02974   1.850\n\nCorrelation of Fixed Effects:\n            (Intr) vcngvc nm_syl spch__\nvoicingvocd -0.029                     \nnum_sylmono -0.163  0.417              \nspeech_rt_c  0.011 -0.006  0.412       \nvcngvcd:nm_  0.130 -0.652 -0.647 -0.006\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggpredict(dur_lm, c(\"voicing\", \"num_syl\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nModel has log-transformed response. Back-transforming predictions to\n  original response scale. Standard errors are still on the transformed\n  scale.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Predicted values of v1_duration\n\nnum_syl: di\n\nvoicing   | Predicted |         95% CI\n--------------------------------------\nvoiceless |    110.79 |  99.01, 123.96\nvoiced    |    131.68 | 116.82, 148.43\n\nnum_syl: mono\n\nvoicing   | Predicted |         95% CI\n--------------------------------------\nvoiceless |    120.33 | 107.53, 134.64\nvoiced    |    151.11 | 134.06, 170.32\n\nAdjusted for:\n* speech_rate_c = -0.18\n*       speaker = 0 (population-level)\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndur_lm_ext <- extend(dur_lm, along = \"speaker\", n = 100)\nfixef(dur_lm_ext)[\"voicingvoiced:num_sylmono\"] <- 0.03\n\nfi <- \"cache/dur_lm_pow.rds\"\n\nif (file.exists(fi)) {\n  dur_lm_pow <- readRDS(fi)\n} else {\n  suppressMessages(\n    dur_lm_pow <- powerCurve(dur_lm_ext, fixed(\"voicing:num_syl\"), along = \"speaker\", breaks = c(50, 70, 100)) \n  )\n  saveRDS(dur_lm_pow, fi)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(dur_lm_pow)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPower for predictor 'voicing:num_syl', (95% confidence interval),\nby number of levels in speaker:\n     50: 83.30% (80.84, 85.56) - 6000 rows\n     70: 92.90% (91.13, 94.41) - 8400 rows\n    100: 98.90% (98.04, 99.45) - 12000 rows\n\nTime elapsed: 1 h 12 m 47 s\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(dur_lm_pow)\n```\n\n::: {.cell-output-display}\n![](01-vowel-duration_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- seq(50, 200, by = 10)\ny <- x + 5\nplot(x, y/x)\n```\n\n::: {.cell-output-display}\n![](01-vowel-duration_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}